import asyncio
import re
import json
import os
import time
import aiohttp
import logging
from datetime import datetime, timezone, timedelta
from telethon import TelegramClient
from telethon.sessions import StringSession
from telethon.tl.types import Channel, ChatInviteAlready, ChatInvite, MessageEntityTextUrl
from telethon.errors import SessionPasswordNeededError, FloodWaitError, RPCError, ChannelPrivateError
from telethon.tl.functions.messages import ImportChatInviteRequest, CheckChatInviteRequest
from urllib.parse import urlparse, parse_qs

# ====== ç”¨æˆ·é…ç½®åŒºåŸŸ ======
API_ID = 27335138
API_HASH = '2459555ba95421148c682e2dc3031bb6'
STRING_SESSION = '1BVtsOJYBuxvWKzU2s5RM2JAvD1OUh0Ks20deYaWNpehYUVvPjAC-As-8DM9yt5_DdsTMOcZ5R-4CL-T6foBVPwJ3pmWlaqW_iBkfChzidstU2OVChHWwvhMEURKBACRJDZT2U6Jr7f-DtbjqQnEK63_OUFAQHpSjNkCVdkLeq9WNCJtLr9zyC660qk5xzPWcjMMREihQGkV6irPtiyX6xgeIjBDqToq4qUcGCir_m4NcZ0cbfHnoeDcYNz9FJGlHaXvBRamE75sQ2PCdGCuUE0-JuW5m6VMMzXZHuUs_R4vPYhUm61P_IsJg4yCljK1txz_rl6TsYqkcofPvhPNv1zm895UUloI='   # ä»https://tgs.252035.xyz/è·å–ï¼ŒæŠŠV1å¡«å…¥ ,å¿…å¡«é¡¹ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼

# è‡ªå®šä¹‰monitor_stateå’Œsent_linksçš„ä¿å­˜è·¯å¾„ï¼ˆå¦‚æœä¸ºç©ºåˆ™ä¿å­˜åœ¨è„šæœ¬æ‰€åœ¨ç›®å½•ï¼‰
SAVE_PATH = ""  # ç¤ºä¾‹: "/path/to/save/directory"

# é¢‘é“é…ç½®ï¼ˆé€—å·éš”å¼€ï¼‰
CHANNEL_URLS = [
    'https://t.me/tianyifc','https://t.me/yp123pan','https://t.me/lubaoty','https://t.me/bh9_527'
]

MONITOR_INTERVAL = 1200  # å¾ªç¯å‘¨æœŸ3600ç§’
DEBUG = False  # è°ƒè¯•æ¨¡å¼å¼€å…³

# API2å¼€å…³ - Trueä¸ºå¯ç”¨ï¼ŒFalseä¸ºç¦ç”¨
ENABLE_API2 = True

# å…¨å±€æ’é™¤å…³é”®è¯
EXCLUDE_KEYWORDS = ['å°ç¨‹åº', 'é¢„å‘Š', 'é¢„æ„Ÿ', 'ç›ˆåˆ©', 'å³å¯è§‚çœ‹', 'ä¹¦ç±', 'ç”µå­ä¹¦', 'å›¾ä¹¦', 'ä¸›ä¹¦', 'æœŸåˆŠ','app','è½¯ä»¶', 'ç ´è§£ç‰ˆ','è§£é”','ä¸“ä¸šç‰ˆ','é«˜çº§ç‰ˆ','æœ€æ–°ç‰ˆ','é£Ÿè°±',
              'å…å®‰è£…', 'å…å¹¿å‘Š','å®‰å“', 'Android', 'è¯¾ç¨‹', 'ä½œå“', 'æ•™ç¨‹', 'æ•™å­¦', 'å…¨ä¹¦', 'åè‘—', 'mobi', 'MOBI', 'epub','ä»»å¤©å ‚','PC','å•æœºæ¸¸æˆ',
              'pdf', 'PDF', 'PPT', 'æŠ½å¥–', 'å®Œæ•´ç‰ˆ', 'æœ‰å£°ä¹¦','è¯»è€…','æ–‡å­¦', 'å†™ä½œ', 'èŠ‚è¯¾', 'å¥—è£…', 'è¯æœ¯', 'çº¯å‡€ç‰ˆ', 'æ—¥å†''txt', 'MP3','ç½‘èµš',
              'mp3', 'WAV', 'CD', 'éŸ³ä¹', 'ä¸“è¾‘', 'æ¨¡æ¿', 'ä¹¦ä¸­', 'è¯»ç‰©', 'å…¥é—¨', 'é›¶åŸºç¡€', 'å¸¸è¯†', 'ç”µå•†', 'å°çº¢ä¹¦','JPG','çŸ­è§†é¢‘','å·¥ä½œæ€»ç»“',
              'å†™çœŸ','æŠ–éŸ³', 'èµ„æ–™', 'åä¸º', 'çŸ­å‰§', 'çºªå½•ç‰‡', 'è®°å½•ç‰‡', 'çºªå½•', 'çºªå®', 'å­¦ä¹ ', 'ä»˜è´¹', 'å°å­¦', 'åˆä¸­','æ•°å­¦', 'è¯­æ–‡', 'å”è¯—','é­”æ³•åå¥³å·«','è½¦è½½','DJ','åˆå¹¶']  # å¯æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šé»‘åå•å…³é”®è¯

# APIé…ç½®åˆ—è¡¨
API_CONFIGS = [
    # API1é…ç½®ï¼ˆæå–å‰§é›†ï¼‰
    {
        'url': "http://192.168.2.17:4567/#/shares/",  #ä»…ä½œç¤ºä¾‹ï¼ŒATå®¿ä¸»æœºIP:å¤–éƒ¨ç«¯å£/api/sharesï¼Œå¿…å¡«é¡¹ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼
        'key': "2879bf4d900f45e5bed3d4167668e4d1",                 #ATé«˜çº§è®¾ç½®ä¸­è·å–ï¼Œå¿…å¡«é¡¹ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼
        'required_keywords': [],  # API1å¿…é¡»å…³é”®è¯
        'optional_keywords': ["å­£", "é›†", "EP","S0","åŠ¨æ¼«"],   # API1å¯é€‰å…³é”®è¯
        'monitor_days': 120,
        'try_join': True,
        'monitor_limit': 2000
    },
    # API2é…ç½®ï¼ˆæå–ç”µå½±ï¼‰
    {
        'url': "http://192.168.2.17:4567/#/shares/",  # åŒAPI1ï¼Œå¿…å¡«é¡¹ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼
        'key': "2879bf4d900f45e5bed3d4167668e4d1",                                     # åŒAPI1ï¼Œå¿…å¡«é¡¹ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼
        'required_keywords': [],                       # API2å¿…é¡»å…³é”®è¯ï¼ˆç©ºï¼‰
        'optional_keywords': ["åŸç›˜", "ç®€ç¹", "ç®€è‹±","ç®€ä¸­","åŒè¯­","REMUX","ç”µå½±"],                       # API2å¯é€‰å…³é”®è¯
        'monitor_days': 300,
        'try_join': True,
        'monitor_limit': 5000
    }
]

# ====== ç”¨æˆ·é…ç½®åŒºåŸŸç»“æŸ ======

# ä¸ºæ¯ä¸ªé¢‘é“åˆ›å»ºç‹¬ç«‹æ ‡è¯†ç¬¦
def get_channel_identifier(channel_url):
    """ç”Ÿæˆé¢‘é“URLçš„å”¯ä¸€æ ‡è¯†ç¬¦"""
    # ç§»é™¤åè®®å’Œç‰¹æ®Šå­—ç¬¦
    identifier = re.sub(r'https?://', '', channel_url)
    identifier = re.sub(r'[^\w\-]', '_', identifier)
    return identifier[:50]  # é™åˆ¶é•¿åº¦

# æ ¹æ®é¢‘é“æ ‡è¯†ç¬¦ç”ŸæˆçŠ¶æ€æ–‡ä»¶å‰ç¼€
def get_state_file(channel_id, api_index, cloud_type):
    """è·å–æŒ‡å®šé¢‘é“ã€APIå’Œäº‘ç›˜ç±»å‹çš„çŠ¶æ€æ–‡ä»¶å"""
    prefix = f"{channel_id}_monitor_state_api"
    if cloud_type == 'tianyi':
        return get_full_path(f"{prefix}{api_index+1}_tianyi.json")
    elif cloud_type == 'uc':
        return get_full_path(f"{prefix}{api_index+1}_uc.json")
    elif cloud_type == '123':  
        return get_full_path(f"{prefix}{api_index+1}_123.json")
    else:
        return None

def get_sent_links_file(channel_id, api_index, cloud_type):
    """è·å–æŒ‡å®šé¢‘é“ã€APIå’Œäº‘ç›˜ç±»å‹çš„å·²å‘é€é“¾æ¥æ–‡ä»¶å"""
    prefix = f"{channel_id}_sent_links_api"
    if cloud_type == 'tianyi':
        return get_full_path(f"{prefix}{api_index+1}_tianyi.json")
    elif cloud_type == 'uc':
        return get_full_path(f"{prefix}{api_index+1}_uc.json")
    elif cloud_type == '123': 
        return get_full_path(f"{prefix}{api_index+1}_123.json")
    else:
        return None

def get_full_path(filename):
    """è·å–å®Œæ•´çš„æ–‡ä»¶è·¯å¾„ï¼ˆè€ƒè™‘è‡ªå®šä¹‰ä¿å­˜è·¯å¾„ï¼‰"""
    if SAVE_PATH and os.path.isdir(SAVE_PATH):
        return os.path.join(SAVE_PATH, filename)
    return filename

# ä¼˜åŒ–æå–ç æ­£åˆ™è¡¨è¾¾å¼ï¼ˆç²¾ç¡®åŒ¹é…4-6ä½å­—ç¬¦ï¼‰
access_pattern = r'(?:å¯†ç |æå–ç |éªŒè¯ç |è®¿é—®ç |åˆ†äº«å¯†ç |å¯†é’¥|pwd|password|share_pwd|pass_code|#)[=:ï¼š\s]*([a-zA-Z0-9]{4,6})(?![a-zA-Z0-9])'

AD_PATTERNS = [
    r'å¤©ç¿¼äº‘ç›˜.*èµ„æºåˆ†äº«',
    r'via\s*ğŸ¤–ç·¨è™Ÿ\s*9527',
    r'ğŸ·?\s*æ ‡ç­¾\s*ï¼š.*',
    r'[ğŸ·#]\s*\w+'
]

UC_AD_PATTERNS = [
    r'UCç½‘ç›˜.*åˆ†äº«',
    r'èµ„æºç¼–å·ï¼š\d+',
    r'ğŸ·ï¸?\s*æ ‡ç­¾\s*ï¼š.*',
    r'[ğŸ·#]\s*\w+'
]

PAN123_AD_PATTERNS = [  
    r'123ç½‘ç›˜.*åˆ†äº«',
    r'èµ„æºç¼–å·ï¼š\d+',
    r'ğŸ·ï¸?\s*æ ‡ç­¾\s*ï¼š.*',
    r'[ğŸ·#]\s*\w+'
]

# ä¿®æ­£ï¼š123ç½‘ç›˜é“¾æ¥æ­£åˆ™è¡¨è¾¾å¼ï¼ˆæ”¯æŒæ›´å¤šæ ¼å¼ï¼‰
PAN123_LINK_PATTERN = r'(?:https?://)?(?:www\.)?(?:123[\d]*|pan\.123)\.com/s/([a-zA-Z0-9\-_]+)'

def clean_task_name(text, cloud_type):
    """æ·±åº¦æ¸…ç†ä»»åŠ¡åç§°ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œå¹¿å‘Šæ–‡æ¡ˆï¼ˆä¿ç•™ç©ºæ ¼ï¼‰"""
    # æ ¹æ®ä¸åŒäº‘ç›˜ç±»å‹ä½¿ç”¨ä¸åŒçš„å¹¿å‘Šæ¨¡å¼
    if cloud_type == 'tianyi':
        patterns = AD_PATTERNS
    elif cloud_type == 'uc':
        patterns = UC_AD_PATTERNS
    elif cloud_type == '123':  
        patterns = PAN123_AD_PATTERNS
    else:
        patterns = []
    
    # ç§»é™¤å¹¿å‘Šæ–‡æ¡ˆ
    for pattern in patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)
    
    # æ ¹æ®ä¸åŒäº‘ç›˜ç±»å‹ç§»é™¤åˆ†äº«é“¾æ¥
    if cloud_type == 'tianyi':
        text = re.sub(r'https?://cloud\.189\.cn/t/[a-zA-Z0-9]{12}', '', text)
        text = re.sub(r'cloud\.189\.cn/t/[a-zA-Z0-9]{12}', '', text)
    elif cloud_type == 'uc':
        text = re.sub(r'https?://drive\.uc\.cn/s/[a-zA-Z0-9\-_]+', '', text)
        text = re.sub(r'drive\.uc\.cn/s/[a-zA-Z0-9\-_]+', '', text)
    elif cloud_type == '123':  
        # ä½¿ç”¨ä¿®æ­£åçš„æ­£åˆ™è¡¨è¾¾å¼
        text = re.sub(PAN123_LINK_PATTERN, '', text, flags=re.IGNORECASE)
    
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ã€å­—æ¯ã€æ•°å­—ã€ç©ºæ ¼å’Œå¸¸ç”¨æ ‡ç‚¹ï¼‰
    # ä¿®æ”¹ï¼šä¿ç•™ç©ºæ ¼å’Œä¸­æ–‡ç©ºæ ¼ï¼ˆ\u3000ï¼‰
    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9,ï¼Œ.ã€‚!ï¼?ï¼Ÿ:ï¼šã€Šã€‹()ï¼ˆï¼‰ã€ã€‘\s\u3000]', '', text)
    
    # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ç‰¹æ®Šç©ºæ ¼ï¼ˆä¿ç•™ä¸­é—´ç©ºæ ¼ï¼‰
    # ä¿®æ”¹ï¼šä¸å†ç§»é™¤æ‰€æœ‰ç©ºæ ¼ï¼Œåªç§»é™¤å¼€å¤´ç»“å°¾çš„ç‰¹æ®Šç©ºæ ¼
    text = re.sub(r'^[\s\u3000]+|[\s\u3000]+$', '', text)
    
    # æˆªæ–­é•¿åº¦è°ƒæ•´ä¸º195ï¼ˆä¸ºåç¼€é¢„ç•™ç©ºé—´ï¼‰
    return text.strip()[:195]

def extract_cloud_info(message):
    """ä»Telegramæ¶ˆæ¯ä¸­æå–äº‘ç›˜åˆ†äº«ä¿¡æ¯ï¼Œæ”¯æŒå¤šé“¾æ¥ç‹¬ç«‹æè¿°å’Œè¶…é“¾æ¥å‚æ•°æå–ç """
    text = message.message
    if not text:
        return []
        
    results = []
    
    # è§£ç URLç¼–ç çš„ç‰¹æ®Šå­—ç¬¦
    decoded_text = text.replace('%EF%BC%88', '(').replace('%EF%BC%89', ')')
    
    # å°è¯•æå–å…¬å…±æ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œæ–‡æœ¬ï¼‰
    lines = decoded_text.split('\n')
    common_title = clean_task_name(lines[0], 'tianyi') if lines else ''  # åˆå§‹ä½¿ç”¨å¤©ç¿¼æ¸…ç†é€»è¾‘
    
    # ä½¿ç”¨ä¼˜åŒ–åçš„æ­£åˆ™è¡¨è¾¾å¼æå–æå–ç 
    access_match = re.search(access_pattern, decoded_text, re.IGNORECASE)
    common_access_code = access_match.group(1) if access_match else None
    
    # 1. æå–å¤©ç¿¼äº‘é“¾æ¥
    tianyi_results = extract_cloud_links(
        decoded_text, 
        common_title,
        common_access_code,
        r'(?:https?://)?cloud\.189\.cn/t/([a-zA-Z0-9]{12})\b',
        'tianyi'
    )
    
    # 2. æå–UCé“¾æ¥
    uc_results = extract_cloud_links(
        decoded_text,
        common_title,
        common_access_code,
        r'drive\.uc\.cn/s/([a-zA-Z0-9\-_]+)([^#]*)?(#*/list/share/([^\?\-]+))?',
        'uc'
    )
    
    # 3. æå–123ç½‘ç›˜é“¾æ¥ï¼ˆæ–°å¢123ç½‘ç›˜æ”¯æŒï¼‰
    # ä½¿ç”¨ä¿®æ­£åçš„æ­£åˆ™è¡¨è¾¾å¼
    pan123_results = extract_cloud_links(
        decoded_text,
        common_title,
        common_access_code,
        PAN123_LINK_PATTERN,  
        '123'
    )
    
    results.extend(tianyi_results)
    results.extend(uc_results)
    results.extend(pan123_results)  
    
    # 4. å¤„ç†æ‰€æœ‰ç±»å‹çš„è¶…é“¾æ¥ï¼ˆå¢å¼ºæå–ç æå–åŠŸèƒ½ï¼‰
    if message.entities:
        for entity in message.entities:
            if isinstance(entity, MessageEntityTextUrl):
                url = entity.url
                # æå–å®ä½“å¯¹åº”çš„æ–‡æœ¬
                entity_text = text[entity.offset:entity.offset+entity.length]
                
                # ä»URLå‚æ•°ä¸­æå–æå–ç ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
                url_access_code = extract_access_code_from_url(url)
                
                # å¤©ç¿¼äº‘é“¾æ¥
                tianyi_match = re.search(r'cloud\.189\.cn/t/([a-zA-Z0-9]{12})', url, re.IGNORECASE)
                if tianyi_match:
                    share_code = tianyi_match.group(1)
                    # æ·»åŠ åˆ°ç»“æœï¼ˆå¦‚æœæœªåŒ…å«ï¼‰
                    if not any(info['share_code'] == share_code and info['cloud_type'] == 'tianyi' for info in results):
                        results.append({
                            'share_code': share_code,
                            'description': entity_text,
                            'access_code': url_access_code or common_access_code,
                            'common_title': common_title,
                            'cloud_type': 'tianyi'
                        })
                
                # UCé“¾æ¥
                uc_match = re.search(r'drive\.uc\.cn/s/([a-zA-Z0-9\-_]+)', url, re.IGNORECASE)
                if uc_match:
                    share_code = uc_match.group(1)
                    # æ·»åŠ åˆ°ç»“æœï¼ˆå¦‚æœæœªåŒ…å«ï¼‰
                    if not any(info['share_code'] == share_code and info['cloud_type'] == 'uc' for info in results):
                        results.append({
                            'share_code': share_code,
                            'description': entity_text,
                            'access_code': url_access_code or common_access_code,
                            'common_title': common_title,
                            'cloud_type': 'uc'
                        })
                
                # ä¿®æ­£ï¼š123ç½‘ç›˜é“¾æ¥æå–ï¼ˆä½¿ç”¨æ›´å…¨é¢çš„æ­£åˆ™ï¼‰
                pan123_match = re.search(PAN123_LINK_PATTERN, url, re.IGNORECASE)
                if pan123_match:
                    share_code = pan123_match.group(1)
                    # æ·»åŠ åˆ°ç»“æœï¼ˆå¦‚æœæœªåŒ…å«ï¼‰
                    if not any(info['share_code'] == share_code and info['cloud_type'] == '123' for info in results):
                        results.append({
                            'share_code': share_code,
                            'description': entity_text,
                            'access_code': url_access_code or common_access_code,
                            'common_title': common_title,
                            'cloud_type': '123'
                        })
    
    return results

def extract_access_code_from_url(url):
    """ä»URLå‚æ•°ä¸­æå–è®¿é—®ç ï¼ˆå¢å¼ºåŠŸèƒ½ï¼‰"""
    # è§£æURLå‚æ•°
    try:
        parsed = urlparse(url)
        query_params = parse_qs(parsed.query)
        
        # æ£€æŸ¥å¯èƒ½çš„æå–ç å‚æ•°å
        for param in ['pwd', 'password', 'access_code', 'code', 'sharepwd']:
            if param in query_params and query_params[param]:
                code = query_params[param][0]
                # éªŒè¯æå–ç æ ¼å¼ï¼ˆ4-6ä½å­—æ¯æ•°å­—ï¼‰
                if re.match(r'^[a-zA-Z0-9]{4,6}$', code):
                    return code
    except Exception:
        pass
    
    # ä½¿ç”¨æ­£åˆ™ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
    pattern = r'[?&](?:pwd|password|access_code|code|sharepwd)=([a-zA-Z0-9]{4,6})'
    match = re.search(pattern, url, re.IGNORECASE)
    return match.group(1) if match else None

def extract_cloud_links(decoded_text, common_title, common_access_code, pattern, cloud_type):
    """æå–ç‰¹å®šäº‘ç›˜çš„é“¾æ¥ï¼ˆå¢å¼ºè®¿é—®ç æå–åŠŸèƒ½ï¼‰"""
    results = []
    # æ·»åŠ å¿½ç•¥å¤§å°å†™æ ‡å¿—ï¼Œç¡®ä¿åŒ¹é…Markdownè¶…é“¾æ¥
    share_matches = re.finditer(pattern, decoded_text, re.IGNORECASE)
    
    for match in share_matches:
        full_url = match.group(0)  # è·å–å®Œæ•´URL
        share_code = match.group(1)
        
        # ä»URLä¸­æå–è®¿é—®ç 
        url_access_code = extract_access_code_from_url(full_url)
        
        # æŸ¥æ‰¾åˆ†äº«ç å‰é¢çš„æè¿°æ–‡æœ¬
        start_index = match.start()
        context_start = max(0, start_index - 100)
        context_text = decoded_text[context_start:start_index]
        
        # å…³é”®ä¿®æ”¹ï¼šä¼˜å…ˆæ£€æŸ¥ä¸Šä¸€è¡Œæ–‡æœ¬
        prev_line = ""
        if '\n' in context_text:
            lines = context_text.split('\n')
            if len(lines) > 1:
                prev_line = lines[-2].strip()  # è·å–ä¸Šä¸€è¡Œæ–‡æœ¬

        # åˆ¤æ–­é€»è¾‘ï¼š
        # 1. å¦‚æœæœ‰ä¸Šä¸€è¡Œæ–‡æœ¬ä¸”é•¿åº¦>=30ï¼Œè§†ä¸ºåˆ†äº«é“¾æ¥çš„æ ‡é¢˜
        # 2. å¦åˆ™è§†ä¸ºæè¿°ï¼Œå­˜åœ¨å…¬å…±æ ‡é¢˜
        if prev_line and len(prev_line) >= 30:
            description = prev_line
            # å½“è¢«è§†ä¸ºæ ‡é¢˜æ—¶ï¼Œæ¸…é™¤å…¬å…±æ ‡é¢˜
            current_common_title = ''
        else:
            # æå–é“¾æ¥å‰çš„æ–‡æœ¬ï¼ˆæœ€å¤š50å­—ç¬¦ï¼‰
            prefix_match = re.search(r'([^\n]{0,50})$', context_text)
            description = prefix_match.group(1).strip() if prefix_match else ""
            # ä¿ç•™å…¬å…±æ ‡é¢˜
            current_common_title = common_title         
        
        # æ¸…ç†æè¿°æ–‡æœ¬ï¼ˆä¿ç•™ç©ºæ ¼ï¼‰
        # ä¿®æ”¹ï¼šä¸å†ç§»é™¤ç©ºæ ¼
        clean_desc = clean_task_name(description, cloud_type)
        
        # ä»ä¸Šä¸‹æ–‡ä¸­æå–è®¿é—®ç ï¼ˆä¼˜å…ˆçº§é«˜äºå…¨å±€è®¿é—®ç ï¼‰
        context_access_match = re.search(access_pattern, context_text, re.IGNORECASE)
        context_access_code = context_access_match.group(1) if context_access_match else None
        
        # ç¡®å®šæœ€ç»ˆçš„è®¿é—®ç ï¼ˆä¼˜å…ˆçº§ï¼šURLå‚æ•° > ä¸Šä¸‹æ–‡ > å…¨å±€ï¼‰
        final_access_code = url_access_code or context_access_code or common_access_code
        
        results.append({
            'share_code': share_code,
            'description': clean_desc,
            'access_code': final_access_code,
            'common_title': current_common_title,
            'cloud_type': cloud_type
        })
    
    return results

def filter_message(text, api_cfg, api_index):
    """æ ¹æ®APIé…ç½®ç­›é€‰æ¶ˆæ¯ï¼ˆä¼˜åŒ–API2é€»è¾‘ï¼‰å¹¶è¿”å›è¿‡æ»¤ç»“æœå’ŒåŸå› """
    required_keywords = api_cfg['required_keywords']
    optional_keywords = api_cfg['optional_keywords']
    reason = ""
    
    # API1: æ ‡å‡†è¿‡æ»¤é€»è¾‘
    if api_index == 0:
        # æ£€æŸ¥å¿…é¡»åŒ…å«çš„å…³é”®è¯
        for keyword in required_keywords:
            if keyword and keyword not in text:
                reason = f"ç¼ºå°‘å¿…é¡»å…³é”®è¯ '{keyword}'"
                return False, reason
        
        # æ£€æŸ¥å¯é€‰å…³é”®è¯ï¼ˆè‡³å°‘åŒ…å«ä¸€ä¸ªï¼‰
        if optional_keywords:
            found_optional = False
            for keyword in optional_keywords:
                if keyword and keyword in text:
                    found_optional = True
                    break
            if not found_optional:
                optional_str = ", ".join([kw for kw in optional_keywords if kw])
                reason = f"æœªæ‰¾åˆ°ä»»ä½•å¯é€‰å…³é”®è¯: [{optional_str}]"
                return False, reason
        
        return True, "æ»¡è¶³æ‰€æœ‰è¿‡æ»¤æ¡ä»¶"
    
    # API2è¿‡æ»¤é€»è¾‘
    elif api_index == 1:
        # 1. åŠ¨æ€æ’é™¤API1çš„å¯é€‰å…³é”®è¯
        api1_optional = API_CONFIGS[0]['optional_keywords']
        
        for keyword in api1_optional:
            if keyword and keyword in text:
                reason = f"åŒ…å«API1æ’é™¤å…³é”®è¯ '{keyword}'"
                return False, reason
        
        # 2. æ£€æŸ¥API2çš„å¿…é¡»å…³é”®è¯ï¼ˆå¦‚æœæœ‰ï¼‰
        for keyword in required_keywords:
            if keyword and keyword not in text:
                reason = f"ç¼ºå°‘å¿…é¡»å…³é”®è¯ '{keyword}'"
                return False, reason
        
        # 3. æ£€æŸ¥API2çš„å¯é€‰å…³é”®è¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if optional_keywords:
            found_optional = False
            for keyword in optional_keywords:
                if keyword and keyword in text:
                    found_optional = True
                    break
            if not found_optional:
                optional_str = ", ".join([kw for kw in optional_keywords if kw])
                reason = f"æœªæ‰¾åˆ°ä»»ä½•å¯é€‰å…³é”®è¯: [{optional_str}]"
                return False, reason
        
        return True, "æ»¡è¶³æ‰€æœ‰è¿‡æ»¤æ¡ä»¶"  # é€šè¿‡æ‰€æœ‰æ£€æŸ¥
    
    return False, "æœªè¯†åˆ«çš„APIç´¢å¼•"

async def connect_telegram_with_retry():
    """å¸¦é‡è¯•æœºåˆ¶çš„Telegramè¿æ¥"""
    max_retries = 5
    retry_delay = 10
    
    for attempt in range(max_retries):
        try:
            client = TelegramClient(
                StringSession(STRING_SESSION), 
                API_ID, 
                API_HASH
            )
            await client.start()
            print("æˆåŠŸè¿æ¥åˆ°Telegram")
            return client
        except SessionPasswordNeededError:
            print("éœ€è¦ä¸¤æ­¥éªŒè¯ï¼Œè¯·åœ¨Telegramåº”ç”¨ä¸­ç¡®è®¤ç™»å½•")
            await client.start(password=lambda: input('è¯·è¾“å…¥ä¸¤æ­¥éªŒè¯å¯†ç : '))
            return client
        except FloodWaitError as e:
            wait_time = e.seconds + 10
            print(f"é‡åˆ°é™æµï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
            await asyncio.sleep(wait_time)
        except RPCError as e:
            print(f"è¿æ¥å¤±è´¥ ({e}), å°è¯• {attempt+1}/{max_retries}")
            await asyncio.sleep(retry_delay)
        except Exception as e:
            print(f"æœªçŸ¥é”™è¯¯: {e}, å°è¯• {attempt+1}/{max_retries}")
            await asyncio.sleep(retry_delay)
    
    print("è¿æ¥å¤±è´¥ï¼Œè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
    return None

def load_processed_messages(channel_id, api_index, cloud_type):
    """åŠ è½½æŒ‡å®šé¢‘é“ã€APIå’Œäº‘ç›˜ç±»å‹çš„å·²å¤„ç†æ¶ˆæ¯ID"""
    state_file = get_state_file(channel_id, api_index, cloud_type)
    if os.path.exists(state_file):
        try:
            with open(state_file, 'r') as f:
                return set(json.load(f))
        except Exception as e:
            print(f"åŠ è½½çŠ¶æ€æ–‡ä»¶{state_file}å¤±è´¥: {e}")
    return set()

def save_processed_messages(processed_ids, channel_id, api_index, cloud_type):
    """ä¿å­˜æŒ‡å®šé¢‘é“ã€APIå’Œäº‘ç›˜ç±»å‹çš„å·²å¤„ç†æ¶ˆæ¯ID"""
    state_file = get_state_file(channel_id, api_index, cloud_type)
    try:
        with open(state_file, 'w') as f:
            json.dump(list(processed_ids), f)
    except Exception as e:
        print(f"ä¿å­˜çŠ¶æ€æ–‡ä»¶{state_file}å¤±è´¥: {e}")

def load_sent_links(channel_id, api_index, cloud_type):
    """åŠ è½½æŒ‡å®šé¢‘é“ã€APIå’Œäº‘ç›˜ç±»å‹çš„å·²å‘é€åˆ†äº«é“¾æ¥è®°å½•"""
    sent_links_file = get_sent_links_file(channel_id, api_index, cloud_type)
    if os.path.exists(sent_links_file):
        try:
            with open(sent_links_file, 'r') as f:
                return set(json.load(f))
        except:
            return set()
    return set()

def save_sent_links(sent_links, channel_id, api_index, cloud_type):
    """ä¿å­˜æŒ‡å®šé¢‘é“ã€APIå’Œäº‘ç›˜ç±»å‹çš„å·²å‘é€åˆ†äº«é“¾æ¥è®°å½•"""
    sent_links_file = get_sent_links_file(channel_id, api_index, cloud_type)
    try:
        with open(sent_links_file, 'w') as f:
            json.dump(list(sent_links), f)
    except Exception as e:
        print(f"ä¿å­˜å·²å‘é€é“¾æ¥è®°å½•åˆ°{sent_links_file}å¤±è´¥: {e}")

async def get_channel_entity(client, channel_url, api_cfg):
    """æ ¹æ®é¢‘é“URLè·å–é¢‘é“å®ä½“"""
    try:
        # å°è¯•ç›´æ¥ä½¿ç”¨å®Œæ•´URLè·å–å®ä½“
        try:
            entity = await client.get_entity(channel_url)
            print(f"æˆåŠŸè·å–é¢‘é“å®ä½“: {entity.title}")
            return entity
        except ValueError:
            pass
        
        # å¤„ç†é‚€è¯·é“¾æ¥æ ¼å¼
        if '+' in channel_url:
            invite_hash = channel_url.split('+')[-1]
            try:
                invite = await client(CheckChatInviteRequest(invite_hash))
                if isinstance(invite, ChatInviteAlready):
                    print(f"å·²åŠ å…¥é¢‘é“: {invite.chat.title}")
                    return invite.chat
                elif isinstance(invite, ChatInvite) and api_cfg['try_join']:
                    print(f"å°è¯•åŠ å…¥ç§æœ‰é¢‘é“: {channel_url}")
                    result = await client(ImportChatInviteRequest(invite_hash))
                    if result and hasattr(result, 'chats') and result.chats:
                        print(f"æˆåŠŸåŠ å…¥é¢‘é“: {result.chats[0].title}")
                        return result.chats[0]
            except Exception as e:
                print(f"å¤„ç†é‚€è¯·é“¾æ¥å¤±è´¥: {e}")
        else:
            username = channel_url.split('/')[-1]
            try:
                entity = await client.get_entity(f"@{username}")
                print(f"æˆåŠŸè·å–é¢‘é“å®ä½“: {entity.title}")
                return entity
            except ValueError:
                entity = await client.get_entity(username)
                print(f"æˆåŠŸè·å–é¢‘é“å®ä½“: {entity.title}")
                return entity
    except ValueError as ve:
        print(f"è·å–é¢‘é“å®ä½“å¤±è´¥(ValueError): {ve}")
    except Exception as e:
        print(f"è·å–é¢‘é“å®ä½“å¤±è´¥: {e}")
    return None

async def send_to_api(api_cfg, share_code, task_name, api_index, cloud_type, access_code=None):
    """å‘é€åˆ†äº«é“¾æ¥åˆ°APIæ¥å£ï¼ˆå¢å¼ºé”™è¯¯å¤„ç†ï¼‰"""
    # æ ¹æ®APIç´¢å¼•æ·»åŠ ç›®å½•å‰ç¼€
    if api_index == 0:
        path_prefix = "è¿½å‰§/"
    elif api_index == 1:
        path_prefix = "ç”µå½±/"
    else:
        path_prefix = ""
    
    # ç»„åˆå®Œæ•´è·¯å¾„ï¼ˆç¡®ä¿ä¸è¶…è¿‡200å­—ç¬¦ï¼‰
    full_path = path_prefix + task_name
    if len(full_path) > 200:
        full_path = full_path[:200]
    
    if cloud_type == 'tianyi':
        share_link = f"https://cloud.189.cn/t/{share_code}"
        cloud_type_id = 9
    elif cloud_type == 'uc':
        share_link = f"https://drive.uc.cn/s/{share_code}"
        cloud_type_id = 7  
    elif cloud_type == '123':  
        # ä½¿ç”¨å›ºå®šåŸŸåæ ¼å¼ï¼Œå®é™…APIä¼šæ­£ç¡®å¤„ç†æ‰€æœ‰123xxx.comåŸŸå
        share_link = f"https://www.123865.com/s/{share_code}"
        cloud_type_id = 3  
    
    payload = {
        "path": full_path,  # ä½¿ç”¨å¸¦å‰ç¼€çš„å®Œæ•´è·¯å¾„
        "shareId": share_code,
        "folderId": "",
        "password": access_code if access_code else "",
        "type": cloud_type_id
    }
    
    headers = {
        "x-api-key": api_cfg['key'],
        "Content-Type": "application/json"
    }
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(api_cfg['url'], json=payload, headers=headers) as response:
                # è·å–HTTPçŠ¶æ€ç 
                status = response.status
                raw_response = await response.text()
                
                try:
                    json_response = json.loads(raw_response)
                except json.JSONDecodeError:
                    json_response = {"raw_response": raw_response}
                
                # ä»…æ£€æŸ¥HTTPçŠ¶æ€ç æ˜¯å¦ä¸º200
                if status == 200:
                    print(f"âœ… æˆåŠŸå‘é€{cloud_type.upper()}é“¾æ¥åˆ°API{api_index+1}: {share_link}")
                    print(f"ä»»åŠ¡åç§°: {full_path}")  # æ˜¾ç¤ºå¸¦å‰ç¼€çš„å®Œæ•´è·¯å¾„
                    print(f"è®¿é—®ç : {access_code or 'æ— '}")
                    print(f"HTTPçŠ¶æ€ç : {status}")
                    if DEBUG:  # ä½¿ç”¨å…¨å±€è°ƒè¯•æ¨¡å¼
                        print("APIè¿”å›å€¼:")
                        print(json.dumps(json_response, indent=2, ensure_ascii=False))
                    return True, json_response
                else:
                    # å¢å¼ºé”™è¯¯ä¿¡æ¯è¾“å‡º
                    error_msg = json_response.get("error", "æœªçŸ¥é”™è¯¯") if isinstance(json_response, dict) else "éJSONå“åº”"
                    print(f"âŒ API{api_index+1}è¿”å›å¤±è´¥({cloud_type.upper()}): {share_link}")
                    print(f"HTTPçŠ¶æ€ç : {status}")
                    print(f"é”™è¯¯ç±»å‹: {error_msg}")
                    print(f"ä»»åŠ¡åç§°: {full_path}")  # æ˜¾ç¤ºå¸¦å‰ç¼€çš„å®Œæ•´è·¯å¾„
                    print(f"è®¿é—®ç : {access_code or 'æ— '}")
                    
                    # æ‰“å°å®Œæ•´çš„æœåŠ¡å™¨å“åº”
                    print(f"å®Œæ•´å“åº”å†…å®¹:")
                    print(raw_response)
                    
                    # è°ƒè¯•æ¨¡å¼ä¸‹æ‰“å°JSONæ ¼å¼çš„å“åº”
                    if DEBUG:
                        print("JSONæ ¼å¼çš„å“åº”:")
                        print(json.dumps(json_response, indent=2, ensure_ascii=False))
                    
                    return False, json_response
    except aiohttp.ClientError as e:
        print(f"âš ï¸ è¯·æ±‚å¤±è´¥({cloud_type.upper()}): {e}, é“¾æ¥: {share_link}")
        print(f"ä»»åŠ¡åç§°: {full_path}")  # æ˜¾ç¤ºå¸¦å‰ç¼€çš„å®Œæ•´è·¯å¾„
        print(f"è®¿é—®ç : {access_code or 'æ— '}")
        return False, {"error": str(e)}
    except Exception as e:
        print(f"âš ï¸ å¤„ç†è¯·æ±‚æ—¶å‡ºé”™({cloud_type.upper()}): {e}, é“¾æ¥: {share_link}")
        print(f"ä»»åŠ¡åç§°: {full_path}")  # æ˜¾ç¤ºå¸¦å‰ç¼€çš„å®Œæ•´è·¯å¾„
        print(f"è®¿é—®ç : {access_code or 'æ— '}")
        return False, {"error": str(e)}

async def process_channel_for_api(client, channel_url, api_cfg, api_index):
    """ä¸ºç‰¹å®šAPIå¤„ç†é¢‘é“æ¶ˆæ¯ï¼ˆæ”¯æŒå¤šé“¾æ¥ç‹¬ç«‹å‘½åå’Œå¤šé¢‘é“ç‹¬ç«‹çŠ¶æ€ï¼‰"""
    # è·å–é¢‘é“æ ‡è¯†ç¬¦
    channel_id = get_channel_identifier(channel_url)
    
    print(f"\nå¤„ç†é¢‘é“: {channel_url} (API{api_index+1})")
    print(f"é¢‘é“ID: {channel_id}")
    print(f"æ—¶é—´èŒƒå›´: {api_cfg['monitor_days']}å¤© | æ¶ˆæ¯é™åˆ¶: {api_cfg['monitor_limit']}æ¡")
    
    # åŠ è½½çŠ¶æ€ï¼ˆä½¿ç”¨é¢‘é“ç‰¹å®šæ–‡ä»¶ï¼‰
    processed_ids_tianyi = load_processed_messages(channel_id, api_index, 'tianyi')
    processed_ids_uc = load_processed_messages(channel_id, api_index, 'uc')
    processed_ids_123 = load_processed_messages(channel_id, api_index, '123')  
    
    # åŠ è½½å·²å‘é€é“¾æ¥ï¼ˆä½¿ç”¨é¢‘é“ç‰¹å®šæ–‡ä»¶ï¼‰
    sent_links_tianyi = load_sent_links(channel_id, api_index, 'tianyi')
    sent_links_uc = load_sent_links(channel_id, api_index, 'uc')
    sent_links_123 = load_sent_links(channel_id, api_index, '123')  
    
    # è®¡æ•°å™¨
    processed_count = 0
    sent_count = 0
    skip_count = 0
    
    # æ–°å¢ï¼šè¯¦ç»†åŸå› ç»Ÿè®¡
    skip_reasons = {
        "global_exclude": {},
        "api_filter": {},
        "no_valid_links": 0,
        "already_sent": 0
    }
    
    try:
        # è·å–é¢‘é“å®ä½“
        entity = await get_channel_entity(client, channel_url, api_cfg)
        if not entity:
            print(f"æ— æ³•è·å–é¢‘é“å®ä½“: {channel_url}")
            return 0, 0
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        now = datetime.now(timezone.utc)
        min_date = now - timedelta(days=api_cfg['monitor_days'])
        print(f"ç›‘æ§æ—¶é—´èŒƒå›´: {min_date.strftime('%Y-%m-%d')} è‡³ {now.strftime('%Y-%m-%d')}")
        
        # æ”¶é›†æ¶ˆæ¯ï¼ˆæŒ‰ç…§å½“å‰APIçš„é™åˆ¶ï¼‰ 
        new_messages = []
        try:
            # ä½¿ç”¨iter_messagesè·å–æ¶ˆæ¯ï¼ˆä½¿ç”¨å½“å‰APIçš„é™åˆ¶ï¼‰
            async for message in client.iter_messages(entity, limit=api_cfg['monitor_limit']):
                # è·³è¿‡å·²å¤„ç†æˆ–è¿‡æœŸçš„æ¶ˆæ¯
                if ((message.id in processed_ids_tianyi and message.id in processed_ids_uc and message.id in processed_ids_123) or 
                    message.date < min_date.replace(tzinfo=timezone.utc)):
                    continue
                
                new_messages.append(message)
                
            print(f"æ‰¾åˆ° {len(new_messages)} æ¡æ»¡è¶³å½“å‰APIé™åˆ¶çš„æ–°æ¶ˆæ¯")
            
        except ChannelPrivateError:
            # ç‰¹æ®Šå¤„ç†ç§æœ‰é¢‘é“
            print(f"æ£€æµ‹åˆ°ç§æœ‰é¢‘é“ï¼Œå°è¯•è·å–æœ€æ–°æ¶ˆæ¯...")
            try:
                async for message in client.iter_messages(entity, limit=100):
                    if ((message.id in processed_ids_tianyi and message.id in processed_ids_uc and message.id in processed_ids_123) or 
                        message.date < min_date.replace(tzinfo=timezone.utc)):
                        continue
                    new_messages.append(message)
                    
                print(f"æ‰¾åˆ° {len(new_messages)} æ¡æ»¡è¶³å½“å‰APIé™åˆ¶çš„æ–°æ¶ˆæ¯")
                
            except Exception as e:
                print(f"è·å–ç§æœ‰é¢‘é“æ¶ˆæ¯å¤±è´¥: {e}")
                return 0, 0
                
        except Exception as e:
            print(f"è·å–æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            return 0, 0
        
        # å¤„ç†æ–°æ¶ˆæ¯
        for msg in new_messages:
            if not msg.text:
                continue
            
            # æ–°å¢ï¼šæ£€æŸ¥æ’é™¤å…³é”®è¯ï¼ˆå…¨å±€è¿‡æ»¤ï¼‰å¹¶è®°å½•å…·ä½“å…³é”®è¯
            excluded_keyword = None
            for exclude_kw in EXCLUDE_KEYWORDS:
                if exclude_kw in msg.text:
                    excluded_keyword = exclude_kw
                    skip_reasons["global_exclude"][excluded_keyword] = skip_reasons["global_exclude"].get(excluded_keyword, 0) + 1
                    print(f"âš ï¸ æ¶ˆæ¯ID={msg.id} åŒ…å«æ’é™¤å…³é”®è¯ '{excluded_keyword}'ï¼Œè·³è¿‡å¤„ç†")
                    processed_ids_tianyi.add(msg.id)
                    processed_ids_uc.add(msg.id)
                    processed_ids_123.add(msg.id)
                    skip_count += 1
                    break
            
            if excluded_keyword:
                continue
            
            # æ‰“å°æ¶ˆæ¯å†…å®¹
            msg_text = msg.text[:100] + '...' if len(msg.text) > 100 else msg.text
            print(f"æ¶ˆæ¯ID={msg.id}, æ—¶é—´={msg.date.astimezone().strftime('%Y-%m-%d %H:%M:%S')}")
            
            # åº”ç”¨å½“å‰APIçš„è¿‡æ»¤è§„åˆ™å¹¶è·å–åŸå› 
            filter_result, filter_reason = filter_message(msg.text, api_cfg, api_index)
            if not filter_result:
                # è®°å½•è¿‡æ»¤åŸå› 
                skip_reasons["api_filter"][filter_reason] = skip_reasons["api_filter"].get(filter_reason, 0) + 1
                print(f"æ¶ˆæ¯ID={msg.id} æœªé€šè¿‡API{api_index+1}è¿‡æ»¤: {filter_reason}ï¼Œæ ‡è®°ä¸ºå·²å¤„ç†")
                processed_ids_tianyi.add(msg.id)
                processed_ids_uc.add(msg.id)
                processed_ids_123.add(msg.id)
                skip_count += 1
                continue
            
            # æå–äº‘ç›˜ä¿¡æ¯
            cloud_infos = extract_cloud_info(msg)
            if not cloud_infos:
                skip_reasons["no_valid_links"] += 1
                print(f"æ¶ˆæ¯ID={msg.id} æœªå‘ç°æœ‰æ•ˆäº‘ç›˜é“¾æ¥ï¼Œæ ‡è®°ä¸ºå·²å¤„ç†")
                processed_ids_tianyi.add(msg.id)
                processed_ids_uc.add(msg.id)
                processed_ids_123.add(msg.id)
                skip_count += 1
                continue
            
            processed_count += 1
            print(f"å‘ç°æœ‰æ•ˆæ¶ˆæ¯: ID={msg.id} (æ»¡è¶³API{api_index+1}è¿‡æ»¤æ¡ä»¶)")
            print(f"åŒ…å« {len(cloud_infos)} ä¸ªåˆ†äº«é“¾æ¥")
            
            # åˆå§‹åŒ–æˆåŠŸæ ‡å¿—
            has_success = False
            all_links_skipped = True  # æ–°å¢ï¼šè·Ÿè¸ªæ‰€æœ‰é“¾æ¥æ˜¯å¦éƒ½æ˜¯è·³è¿‡çŠ¶æ€
            
            # å¤„ç†æ¯ä¸ªäº‘ç›˜é“¾æ¥
            for cloud_info in cloud_infos:
                cloud_type = cloud_info['cloud_type']
                share_code = cloud_info['share_code']
                description = cloud_info['description']
                access_code = cloud_info.get('access_code')
                common_title = cloud_info.get('common_title', '')
                
                # è·å–å½“å‰äº‘ç›˜ç±»å‹çš„å·²å¤„ç†IDå’Œå·²å‘é€é“¾æ¥
                if cloud_type == 'tianyi':
                    processed_ids = processed_ids_tianyi
                    sent_links = sent_links_tianyi
                elif cloud_type == 'uc':
                    processed_ids = processed_ids_uc
                    sent_links = sent_links_uc
                elif cloud_type == '123': 
                    processed_ids = processed_ids_123
                    sent_links = sent_links_123
                
                # æ¸…ç†æè¿°æ–‡æœ¬ï¼ˆä¿ç•™ç©ºæ ¼ï¼‰
                # ä¿®æ”¹ï¼šè°ƒç”¨clean_task_nameå‡½æ•°ï¼ˆå·²ä¿®æ”¹ä¸ºä¿ç•™ç©ºæ ¼ï¼‰
                clean_desc = clean_task_name(description, cloud_type) if description else ""
                
                # æ„å»ºä»»åŠ¡åç§°
                if common_title and clean_desc:
                    # å½“æ¸…ç†åçš„æè¿°ä¸å…¬å…±æ ‡é¢˜ä¸åŒæ—¶åˆå¹¶
                    if clean_desc != common_title:
                        task_name = f"{common_title}+{clean_desc}"
                    else:
                        task_name = common_title
                elif common_title:
                    task_name = common_title
                elif clean_desc:
                    task_name = clean_desc
                else:
                    task_name = f"{cloud_type.upper()}äº‘èµ„æºåˆ†äº«"
                
                # è¿½åŠ åˆ†äº«ç åç¼€ç¡®ä¿å”¯ä¸€æ€§
                task_name = f"{task_name}_{share_code[-4:]}"  
                task_name = task_name[:200]  # æœ€ç»ˆé•¿åº¦æ§åˆ¶
                
                # ç”Ÿæˆåˆ†äº«é“¾æ¥
                if cloud_type == 'tianyi':
                    share_link = f"https://cloud.189.cn/t/{share_code}"
                elif cloud_type == 'uc':
                    share_link = f"https://drive.uc.cn/s/{share_code}"
                elif cloud_type == '123':  
                    share_link = f"https://www.123865.com/s/{share_code}"
                
                # æ£€æŸ¥æ˜¯å¦å·²å‘é€è¿‡ï¼ˆå½“å‰APIï¼‰
                if share_link in sent_links:
                    skip_reasons["already_sent"] += 1
                    print(f"â­ï¸ è·³è¿‡API{api_index+1}å·²å‘é€çš„{cloud_type.upper()}é“¾æ¥: {task_name} - {share_link}")
                    has_success = True  # å·²å‘é€è¿‡çš„é“¾æ¥è§†ä¸ºæˆåŠŸ
                    continue
                
                all_links_skipped = False  # è‡³å°‘æœ‰ä¸€ä¸ªé“¾æ¥éœ€è¦å¤„ç†
                
                # å‘é€åˆ°å½“å‰API
                api_success, _ = await send_to_api(
                    api_cfg, share_code, task_name, api_index, 
                    cloud_type, access_code
                )
                
                if api_success:
                    sent_links.add(share_link)
                    sent_count += 1
                    has_success = True  # æ ‡è®°è‡³å°‘æœ‰ä¸€ä¸ªæˆåŠŸ
                    print(f"âœ… å·²è®°å½•{cloud_type.upper()}é“¾æ¥åˆ°API{api_index+1}: {share_link}")
                    print(f"ä»»åŠ¡åç§°: {task_name}")  # æ³¨æ„ï¼šè¿™é‡Œæ˜¾ç¤ºåŸå§‹ä»»åŠ¡åï¼Œä½†å‘é€çš„å®é™…è·¯å¾„å¸¦å‰ç¼€
                else:
                    print(f"âš ï¸ å‘é€{cloud_type.upper()}é“¾æ¥å¤±è´¥: {share_link}")
            
            # å¤„ç†æˆåŠŸçŠ¶æ€
            if has_success:
                processed_ids_tianyi.add(msg.id)
                processed_ids_uc.add(msg.id)
                processed_ids_123.add(msg.id)
                if all_links_skipped:
                    print(f"æ¶ˆæ¯ID={msg.id} æ‰€æœ‰é“¾æ¥éƒ½å·²å‘é€è¿‡ï¼Œæ ‡è®°ä¸ºå·²å¤„ç†")
                else:
                    print(f"æ¶ˆæ¯ID={msg.id} è‡³å°‘æœ‰ä¸€ä¸ªé“¾æ¥å‘é€æˆåŠŸï¼Œæ ‡è®°ä¸ºå·²å¤„ç†")
            else:
                print(f"æ¶ˆæ¯ID={msg.id} æ‰€æœ‰é“¾æ¥å‘é€å¤±è´¥ï¼Œå°†ä¿ç•™ä»¥ä¾¿ä¸‹æ¬¡å°è¯•")
        
        # ä¿å­˜çŠ¶æ€ï¼ˆä½¿ç”¨é¢‘é“ç‰¹å®šæ–‡ä»¶ï¼‰
        save_processed_messages(processed_ids_tianyi, channel_id, api_index, 'tianyi')
        save_processed_messages(processed_ids_uc, channel_id, api_index, 'uc')
        save_processed_messages(processed_ids_123, channel_id, api_index, '123')  
        save_sent_links(sent_links_tianyi, channel_id, api_index, 'tianyi')
        save_sent_links(sent_links_uc, channel_id, api_index, 'uc')
        save_sent_links(sent_links_123, channel_id, api_index, '123')  
        
        # æ–°å¢ï¼šAPIå¤„ç†åçš„è¯¦ç»†ç»Ÿè®¡ï¼ˆå¢åŠ ä¸œå…«åŒºæ—¶é—´æˆ³ï¼‰[[38][37]]
        # è·å–ä¸œå…«åŒºå½“å‰æ—¶é—´
        tz_east8 = timezone(timedelta(hours=8))
        current_time = datetime.now(tz_east8).strftime("%Y-%m-%d %H:%M:%S")
        
        print(f"\nğŸ“… å¤„ç†å®Œæˆæ—¶é—´ï¼ˆä¸œå…«åŒºï¼‰: {current_time}")
        print(f"ğŸ“Š API{api_index+1} å¤„ç†æ±‡æ€»ç»Ÿè®¡:")
        print(f"âœ“ å¤„ç†æ¶ˆæ¯æ€»æ•°: {len(new_messages)}")
        print(f"âœ“ è·³è¿‡æ¶ˆæ¯æ•°: {skip_count}")
        print(f"âœ“ æˆåŠŸå¤„ç†æ¶ˆæ¯æ•°: {processed_count}")
        print(f"âœ“ å‘é€é“¾æ¥æ•°: {sent_count}")
        
        if skip_reasons["global_exclude"]:
            print("\nâ›” æ’é™¤å…³é”®è¯ç»Ÿè®¡:")
            for keyword, count in skip_reasons["global_exclude"].items():
                print(f"  - åŒ…å« '{keyword}': {count} æ¡")
        
        if skip_reasons["api_filter"]:
            print("\nâš ï¸ APIè¿‡æ»¤åŸå› ç»Ÿè®¡:")
            for reason, count in skip_reasons["api_filter"].items():
                print(f"  - {reason}: {count} æ¡")
        
        if skip_reasons["no_valid_links"] > 0:
            print(f"\nğŸ” æœªå‘ç°æœ‰æ•ˆäº‘ç›˜é“¾æ¥: {skip_reasons['no_valid_links']} æ¡")
        
        if skip_reasons["already_sent"] > 0:
            print(f"\nâ­ï¸ å·²å‘é€é“¾æ¥è·³è¿‡: {skip_reasons['already_sent']} ä¸ª")
        
        return processed_count, sent_count
    
    except Exception as e:
        print(f"å¤„ç†é¢‘é“ {channel_url} æ—¶å‡ºé”™: {e}")
        return processed_count, sent_count

async def continuous_monitoring():
    """æŒç»­ç›‘æ§é¢‘é“çš„æ–°æ¶ˆæ¯ï¼ˆæ”¯æŒå¤šAPIå¤„ç†ï¼‰"""
    # æ¯ä¸ªAPIä½¿ç”¨ç‹¬ç«‹çš„çŠ¶æ€
    while True:
        # è·å–ä¸œå…«åŒºå½“å‰æ—¶é—´
        tz_east8 = timezone(timedelta(hours=8))
        current_time = datetime.now(tz_east8).strftime("%Y-%m-%d %H:%M:%S")
        print(f"\nâ° {current_time} - å¼€å§‹ç›‘æ§å‘¨æœŸ")
        
        client = await connect_telegram_with_retry()
        if not client:
            print("æ— æ³•è¿æ¥Telegramï¼Œç­‰å¾…ä¸‹ä¸€ä¸ªå‘¨æœŸ...")
            await asyncio.sleep(MONITOR_INTERVAL)
            continue
        
        try:
            total_processed = 0
            total_sent = 0
            
            # å¤„ç†æ¯ä¸ªAPIé…ç½®
            for api_index, api_cfg in enumerate(API_CONFIGS):
                # å¦‚æœAPI2è¢«ç¦ç”¨ä¸”å½“å‰æ˜¯API2åˆ™è·³è¿‡
                if api_index == 1 and not ENABLE_API2:
                    continue
                
                # å¤„ç†æ¯ä¸ªé¢‘é“
                for channel_url in CHANNEL_URLS:
                    processed, sent = await process_channel_for_api(client, channel_url, api_cfg, api_index)
                    total_processed += processed
                    total_sent += sent
            
            print(f"\nğŸ”š ç›‘æ§å‘¨æœŸå®Œæˆ")
            print(f"æ€»å¤„ç†æ¶ˆæ¯: {total_processed} | æ€»å‘é€é“¾æ¥: {total_sent}")
            
        except Exception as e:
            print(f"ç›‘æ§è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            await client.disconnect()
        
        print(f"\nâ³ ç­‰å¾… {MONITOR_INTERVAL} ç§’åå¼€å§‹ä¸‹ä¸€æ¬¡ç›‘æ§...")
        await asyncio.sleep(MONITOR_INTERVAL)

if __name__ == '__main__':
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥ï¼ˆWindowsç³»ç»Ÿéœ€è¦ï¼‰
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    
    # è¿è¡Œç›‘æ§
    try:
        asyncio.run(continuous_monitoring())
    except KeyboardInterrupt:
        print("\nç›‘æ§å·²åœ